{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Analysis: Seasonal Effects with Sklearn Linear Regression\n",
    "In this notebook, you will build a SKLearn linear regression model to predict Yen futures (\"settle\") returns with *lagged* CAD/JPY exchange rate returns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currency pair exchange rates for CAD/JPY\n",
    "cad_jpy_df = pd.read_csv(\n",
    "    Path(\"cad_jpy.csv\"), index_col=\"Date\", infer_datetime_format=True, parse_dates=True\n",
    ")\n",
    "cad_jpy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim the dataset to begin on January 1st, 1990\n",
    "cad_jpy_df = cad_jpy_df.loc[\"1990-01-01\":, :]\n",
    "cad_jpy_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a series using \"Price\" percentage returns, drop any nan\"s, and check the results:\n",
    "# (Make sure to multiply the pct_change() results by 100)\n",
    "# In this case, you may have to replace inf, -inf values with np.nan\"s\n",
    "cad_jpy_df['Return'] = (cad_jpy_df[[\"Price\"]].pct_change() * 100)\n",
    "returns = cad_jpy_df.replace(-np.inf, np.nan).dropna()\n",
    "returns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lagged Returns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a lagged return using the shift function\n",
    "cad_jpy_df['Lagged_Return'] = cad_jpy_df[\"Return\"].shift()\n",
    "cad_jpy_df = cad_jpy_df.dropna()\n",
    "cad_jpy_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train/test split for the data using 2018-2019 for testing and the rest for training\n",
    "train = cad_jpy_df[:'2017']\n",
    "test = cad_jpy_df['2018':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create four dataframes:\n",
    "# X_train (training set using just the independent variables), X_test (test set of of just the independent variables)\n",
    "# Y_train (training set using just the \"y\" variable, i.e., \"Futures Return\"), Y_test (test set of just the \"y\" variable):\n",
    "X_train = train[\"Lagged_Return\"].to_frame()\n",
    "y_train = train[\"Return\"]\n",
    "X_test = test[\"Lagged_Return\"].to_frame()\n",
    "y_test = test[\"Return\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the X_train data\n",
    "X_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Linear Regression model and fit it to the training data\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Fit a SKLearn linear regression using  just the training set (X_train, Y_train):\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions using the Testing Data\n",
    "\n",
    "**Note:** We want to evaluate the model using data that it has never seen before, in this case: `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction of \"y\" values using just the test dataset\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble actual y data (Y_test) with predicted y data (from just above) into two columns in a dataframe:\n",
    "Results = y_test.to_frame()\n",
    "Results[\"Predicted Return\"] = predictions\n",
    "Results.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first 20 predictions vs the true values\n",
    "Results[:20].plot(subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out-of-Sample Performance\n",
    "\n",
    "Evaluate the model using \"out-of-sample\" data (`X_test` and `y_test`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "# Calculate the mean_squared_error (MSE) on actual versus predicted test \"y\" \n",
    "# (Hint: use the dataframe from above)\n",
    "out_sample_mse = mean_squared_error(\n",
    "    Results[\"Return\"],\n",
    "    Results[\"Predicted Return\"]\n",
    ")\n",
    "# Using that mean-squared-error, calculate the root-mean-squared error (RMSE):\n",
    "out_sample_rmse = np.sqrt(out_sample_mse)\n",
    "print(f\"Out-of-Sample Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-Sample Performance\n",
    "\n",
    "Evaluate the model using in-sample data (X_train and y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a dataframe using just the \"y\" training data:\n",
    "in_sample_results = y_train.to_frame()\n",
    "# Add a column of \"in-sample\" predictions to that dataframe:  \n",
    "in_sample_results[\"In-sample Predictions\"] = model.predict(X_train)\n",
    "# Calculate in-sample mean_squared_error (for comparison to out-of-sample)\n",
    "in_sample_mse = mean_squared_error(\n",
    "    in_sample_results[\"Return\"],\n",
    "    in_sample_results[\"In-sample Predictions\"]\n",
    ")\n",
    "\n",
    "# Calculate in-sample root mean_squared_error (for comparison to out-of-sample)\n",
    "in_sample_rmse = np.sqrt(in_sample_mse)\n",
    "print(f\"In-sample Root Mean Squared Error (RMSE): {in_sample_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Does this model perform better or worse on out-of-sample data as compared to in-sample data?\n",
    "\n",
    "**Answer:** YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Out of sample data has a smaller RMSE, since a lower score indicates a better fit, we can say it is more aacurate than in sample data."
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
